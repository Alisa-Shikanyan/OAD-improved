# -*- coding: utf-8 -*-
"""
Created on Fri Jun  3 11:42:47 2022

@author: Алиса
"""

#про дзшку по нейросетям сем 03.06
"""
домашка начинается после слова "нейросети", в основном надо работать в ячейке 18
он написал data.columns, сказал что label это результат(?? видимо имя частицы)

в строчке model.fit нейросеть и обучается
чето ghost particles это то что не удалось определить
в ячейке 19 смотрим что получилось (как обычно делим на тестовую и обучающую, качество модели чекаем на тестовой)

чето там roc auc считает для частица против всех остальных, нас интересует короче электрон или не электрон
чел сказал что можно даже из 19 ячейки выкинуть цикл и чекать только для электрона
результат будет в ячейке 20, надо чтобы electron auc был больше 0.97

про данные: -999 это пропуск данных, штуки в ячейке flag могут быть или 0 или 1;
чел такой: попробуйте поработать с данными перед тем как крутить параметры (почекать пропуски и выбросы)
одна из методик - выкинуть все колонки с пропуском (но выкинется дофига), другой вариант - дать этому какое-то значение (среднее/медиану)
еще мб выбросы соответствуют какой-то частице? надо посмотреть
в том числе чето там describe из pandas про пропуски? я хз

как работать с данными которые выдают текст? надо их в какое-то число бахнуть чтобы было удобнее
самый простой метод - присвоить классу номер, на sklearn это чето label encoder (??)
в нашем случае это норм вещь, но если это был бы параметр - было бы плохо

имеет смысл чекать корелляцию (как в ячейке 8), в нашем случае для электрона

чето там как посмотреть все и сразу - построить корелляционную матрицу (они строят в 12)
что-то там можно юзать метод главных компонент, но без флагов

нам надо аппроксимировать функцию ошибок (? то что добавил ?) какой-то функцией
чел после 12 - логистическая регрессия - добавил
from sklearn.preprocessing import StandartScalar
sc = StandartScalar()
x_train_sc = sc.fit_transform(x_train)
x_test_sc = sc.transform(x_test)


есть скейлинг - чтобы все было в одном диапазоне
StandasrtSclar как раз делает что чето в пределах от нуля до единицы, как раз фигачит одинаковые веса я хз

дальше нейросети скейлинг не делался (с)

//от 10.06
что можно менять? слои, количество эпох epochs (типа количество шагов градиентного спуска, сколько раз пропускаем данные для обучения),
                    размер батча batch_size

"""